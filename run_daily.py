#!/usr/bin/env python3
"""
============================================================
æ¯æ—¥æ•°æ®æ‹‰å–è„šæœ¬
============================================================

åŠŸèƒ½ï¼š
    1. æ‹‰å–æ²ªé•ã€ä¸é”ˆé’¢çš„æ—¥çº¿è¡Œæƒ…
    2. æ‹‰å–ç¾å…ƒæŒ‡æ•°
    3. ä¿å­˜ä¸º CSV æ–‡ä»¶
    4. æ£€æµ‹å¼‚å¸¸æ³¢åŠ¨å¹¶è¾“å‡ºæé†’

ä½¿ç”¨æ–¹æ³•ï¼š
    cd nickel_research
    python run_daily.py

åç»­å¯ä»¥ç”¨ crontab è®¾ç½®æ¯å¤©è‡ªåŠ¨æ‰§è¡Œï¼š
    # æ¯å¤©ä¸‹åˆ4ç‚¹æ‰§è¡Œï¼ˆæ”¶ç›˜åï¼‰
    0 16 * * 1-5 cd /ä½ çš„è·¯å¾„/nickel_research && python run_daily.py
============================================================
"""

import sys
import os
import json
import csv
from datetime import datetime, timedelta

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.settings import (
    IFIND_REFRESH_TOKEN, WATCH_LIST,
    RAW_DIR, PROCESSED_DIR, LOG_DIR,
    PRICE_ALERT_THRESHOLD, OI_ALERT_THRESHOLD,
    NICKEL_MAIN, SS_MAIN
)
from src.data_fetcher.ths_client import TonghuashunClient

import logging

# æ—¥å¿—é…ç½®
os.makedirs(LOG_DIR, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(LOG_DIR, f"daily_{datetime.now().strftime('%Y%m%d')}.log"),
                          encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def fetch_daily_quotes(client: TonghuashunClient):
    """æ‹‰å–æ—¥çº¿è¡Œæƒ…æ•°æ®"""
    today = datetime.now().strftime("%Y-%m-%d")
    # æ‹‰æœ€è¿‘60å¤©çš„æ•°æ®ï¼ˆç”¨äºè®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼‰
    start = (datetime.now() - timedelta(days=90)).strftime("%Y-%m-%d")
    codes = ",".join(WATCH_LIST)

    logger.info(f"æ‹‰å–æ—¥çº¿è¡Œæƒ…: {codes}, {start} ~ {today}")

    result = client.get_history_quotes(
        codes=codes,
        indicators="open,high,low,close,volume,amount,openInterest,changeRatio",
        start_date=start,
        end_date=today
    )

    return result


def save_quotes_to_csv(result: dict):
    """å°†è¡Œæƒ…æ•°æ®ä¿å­˜ä¸º CSV"""
    os.makedirs(RAW_DIR, exist_ok=True)

    if 'tables' not in result:
        logger.error("è¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸ï¼Œæ²¡æœ‰ tables å­—æ®µ")
        return []

    saved_files = []
    for table in result['tables']:
        code = table.get('thscode', 'unknown')
        time_list = table.get('time', [])
        data = table.get('table', {})

        if not time_list:
            logger.warning(f"{code}: æ²¡æœ‰æ•°æ®")
            continue

        # æ–‡ä»¶åï¼šå¦‚ niZL_SHF_daily.csv
        safe_code = code.replace('.', '_')
        filename = f"{safe_code}_daily.csv"
        filepath = os.path.join(RAW_DIR, filename)

        # æ„å»ºè¡Œæ•°æ®
        indicators = list(data.keys())
        rows = []
        for i in range(len(time_list)):
            row = {'date': time_list[i]}
            for ind in indicators:
                vals = data[ind]
                row[ind] = vals[i] if i < len(vals) else None
            rows.append(row)

        # å†™å…¥ CSV
        fieldnames = ['date'] + indicators
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rows)

        logger.info(f"  ä¿å­˜: {filepath} ({len(rows)} æ¡)")
        saved_files.append((code, filepath, rows))

    return saved_files


def check_alerts(saved_files: list):
    """æ£€æµ‹å¼‚å¸¸æ³¢åŠ¨"""
    alerts = []

    for code, filepath, rows in saved_files:
        if len(rows) < 2:
            continue

        latest = rows[-1]
        prev = rows[-2]

        # æ¶¨è·Œå¹…æ£€æµ‹
        if latest.get('close') and prev.get('close'):
            try:
                change_pct = (float(latest['close']) - float(prev['close'])) / float(prev['close']) * 100
                if abs(change_pct) >= PRICE_ALERT_THRESHOLD:
                    direction = "ğŸ“ˆ ä¸Šæ¶¨" if change_pct > 0 else "ğŸ“‰ ä¸‹è·Œ"
                    alert_msg = (
                        f"âš ï¸ ä»·æ ¼å¼‚å¸¸æ³¢åŠ¨ | {code}\n"
                        f"  {direction} {abs(change_pct):.2f}%\n"
                        f"  æ”¶ç›˜ä»·: {latest['close']} (å‰æ—¥: {prev['close']})\n"
                        f"  æ—¥æœŸ: {latest['date']}"
                    )
                    alerts.append(alert_msg)
                    logger.warning(alert_msg)
            except (ValueError, TypeError):
                pass

        # æŒä»“é‡å˜åŒ–æ£€æµ‹
        if latest.get('openInterest') and prev.get('openInterest'):
            try:
                oi_change = (float(latest['openInterest']) - float(prev['openInterest'])) / float(prev['openInterest']) * 100
                if abs(oi_change) >= OI_ALERT_THRESHOLD:
                    direction = "å¢ä»“" if oi_change > 0 else "å‡ä»“"
                    alert_msg = (
                        f"âš ï¸ æŒä»“é‡å¼‚å¸¸ | {code}\n"
                        f"  {direction} {abs(oi_change):.2f}%\n"
                        f"  æŒä»“é‡: {latest['openInterest']} (å‰æ—¥: {prev['openInterest']})\n"
                        f"  æ—¥æœŸ: {latest['date']}"
                    )
                    alerts.append(alert_msg)
                    logger.warning(alert_msg)
            except (ValueError, TypeError):
                pass

    return alerts


def print_daily_summary(saved_files: list):
    """æ‰“å°æ¯æ—¥è¡Œæƒ…æ‘˜è¦"""
    print("\n" + "=" * 70)
    print(f"ğŸ“Š æ¯æ—¥è¡Œæƒ…æ‘˜è¦ | {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print("=" * 70)

    for code, filepath, rows in saved_files:
        if not rows:
            continue

        latest = rows[-1]
        print(f"\n{'â”€' * 50}")

        # å“ç§åç§°æ˜ å°„
        name_map = {
            NICKEL_MAIN: "æ²ªé•ä¸»åŠ›",
            SS_MAIN: "ä¸é”ˆé’¢ä¸»åŠ›",
        }
        name = name_map.get(code, code)
        print(f"  {name} ({code})")
        print(f"  æ—¥æœŸ: {latest.get('date', 'N/A')}")

        close = latest.get('close', 'N/A')
        open_p = latest.get('open', 'N/A')
        high = latest.get('high', 'N/A')
        low = latest.get('low', 'N/A')
        vol = latest.get('volume', 'N/A')
        oi = latest.get('openInterest', 'N/A')

        print(f"  å¼€ç›˜: {open_p}  |  æœ€é«˜: {high}  |  æœ€ä½: {low}  |  æ”¶ç›˜: {close}")
        print(f"  æˆäº¤é‡: {vol}  |  æŒä»“é‡: {oi}")

        # è®¡ç®—æ¶¨è·Œå¹…
        if len(rows) >= 2 and latest.get('close') and rows[-2].get('close'):
            try:
                change = float(latest['close']) - float(rows[-2]['close'])
                change_pct = change / float(rows[-2]['close']) * 100
                emoji = "ğŸ”´" if change < 0 else "ğŸŸ¢"
                print(f"  æ¶¨è·Œ: {emoji} {change:+.0f} ({change_pct:+.2f}%)")
            except (ValueError, TypeError):
                pass

    print(f"\n{'=' * 70}")


def main():
    logger.info("=" * 50)
    logger.info("å¼€å§‹æ¯æ—¥æ•°æ®æ‹‰å–")
    logger.info("=" * 50)

    # æ£€æŸ¥ token
    if not IFIND_REFRESH_TOKEN or IFIND_REFRESH_TOKEN == "åœ¨è¿™é‡Œå¡«å†™ä½ çš„refresh_token":
        print("âŒ è¯·å…ˆé…ç½® refresh_token!")
        print("   ç¼–è¾‘ config/settings.py æˆ–è¿è¡Œ python test_api.py")
        return

    # åˆ›å»ºå®¢æˆ·ç«¯
    client = TonghuashunClient(IFIND_REFRESH_TOKEN)

    # æ‹‰å–æ•°æ®
    result = fetch_daily_quotes(client)

    # ä¿å­˜æ•°æ®
    saved_files = save_quotes_to_csv(result)

    if not saved_files:
        logger.error("æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
        return

    # æ‰“å°æ‘˜è¦
    print_daily_summary(saved_files)

    # æ£€æµ‹å¼‚å¸¸
    alerts = check_alerts(saved_files)

    if alerts:
        print(f"\nğŸš¨ å‘ç° {len(alerts)} æ¡å¼‚å¸¸æé†’:")
        for a in alerts:
            print(a)
    else:
        print("\nâœ… æœªå‘ç°å¼‚å¸¸æ³¢åŠ¨")

    logger.info("æ¯æ—¥æ•°æ®æ‹‰å–å®Œæˆ")


if __name__ == "__main__":
    main()
